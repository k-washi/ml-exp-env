version: '3'

services:
  ml-dev:
    build: .
    container_name: ml-dev
    image: ml-dev-image
    shm_size: '24gb'
    tty: true
    volumes: 
      - $PWD:/workspace
    command: '/bin/bash'
    ports:
      - 18081-18090:18081-18090
    #runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [gpu]